{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6322,"databundleVersionId":868312,"sourceType":"competition"},{"sourceId":938046,"sourceType":"datasetVersion","datasetId":503255},{"sourceId":5580614,"sourceType":"datasetVersion","datasetId":3211824}],"dockerImageVersionId":30715,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nimport shutil\nfrom PIL import Image\nfrom matplotlib.image import imread\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.utils import image_dataset_from_directory\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\n\npath = \"../input/planets-dataset/\"\nos.listdir(path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading the image datasets\ntrain_path = '../input/planets-dataset/planet/planet/train_classes.csv'\ntest_path = '../input/planets-dataset/planet/planet/sample_submission.csv'\ntrain_images = '../input/planets-dataset/planet/planet/train-jpg'\ntest_images = '../input/planets-dataset/planet/planet/test-jpg'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/planets-dataset/planet/planet/train_classes.csv\")\nprint(train_df.shape)\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(r\"/kaggle/input/planets-dataset/planet/planet/sample_submission.csv\")\nprint(test_df.shape)\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's view some images\nplt.figure(figsize=(20,20))\n# define location of dataset\nfolder = train_images\n# plot first few images\nfor i in range(9):\n    # define subplot\n    plt.subplot(330 + 1 + i)\n    # define filename\n    filename = folder+ \"/\" + 'train_' + str(i) + '.jpg'\n    # load image pixels\n    image = imread(filename)\n    # plot raw pixel data\n    plt.imshow(image)\n# show the figure\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of images in the dataset\nprint(f'Number of images: {train_df.shape[0]}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get number of unique classes in the train dataset\ntrain_df['tags'].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tags present in the dataset\ntags = train_df['tags'].apply(lambda x: x.split(' '))\ntags = [item for sublist in tags for item in sublist]\ntag_counts = pd.Series(tags).value_counts()\n\n# Plot the tags\nplt.figure(figsize=(10,6))\nplt.bar(tag_counts.index, tag_counts.values, alpha=0.8)\nplt.title('Tag counts')\nplt.ylabel('Number of occurrences', fontsize=12)\nplt.xlabel('Tags', fontsize=12)\nplt.xticks(rotation=90)\nplt.show();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = set()\ndef splitting_tags(tags):\n    '''\n    Takes in tags column, splits the tags and store as a set\n    '''\n    [labels.add(tag) for tag in tags.split()]\n    \n# Create a copy of `train_df`\ntrain_df1 = train_df.copy()\ntrain_df1['tags'].apply(splitting_tags)\nlabels = list(labels)\nprint(labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##One hot encoding is performed on the labels in train classes \nfor tag in labels:\n    train_df1[tag] = train_df1['tags'].apply(lambda x: 1 if tag in x.split() else 0)\n    \n## adding .jpg extension to the column image_name so as to have same name format as the image files\ntrain_df1['image_name'] = train_df1['image_name'].apply(lambda x: '{}.jpg'.format(x))\ntrain_df1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the columns\ncolumns = list(train_df1.columns[2:])\ncolumns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale = 1./255., \n    validation_split = 0.2,\n    rotation_range=40,\n    width_shift_range=0.3,\n    height_shift_range=0.3,\n    shear_range=0.3,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Generating train data generator \ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_df1,\n    directory =train_images, \n    x_col='image_name',\n    y_col=columns, \n    subset='training', \n    batch_size=64,\n    seed=42, \n    shuffle=True, \n    class_mode='raw',\n    target_size=(256,256)\n)\n\n#generating validation data which is expected to be 20% of the train dataset since validation split is 0.2\nval_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_df1,\n    directory =train_images, \n    x_col='image_name',\n    y_col=columns,\n    subset='validation', \n    batch_size=32,\n    seed=42, \n    shuffle=True, \n    class_mode='raw',\n    target_size=(256,256)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#setting up step size for training and validation image data\nstep_train_size = int(np.ceil(train_generator.samples / train_generator.batch_size))\nstep_val_size = int(np.ceil(val_generator.samples / val_generator.batch_size))\nprint(step_train_size , step_val_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential([\n    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.MaxPooling2D(),\n    # Flatten layer\n    layers.Conv2D(512, (3,3), activation='relu'),\n    layers.Flatten(),\n    # Fully connected layers\n    layers.Dense(17, activation='softmax'),  \n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(\n    optimizer='sgd', \n    loss='categorical_crossentropy', \n    metrics=['accuracy','FBetaScore', 'CategoricalAccuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"call_backs = EarlyStopping(\n    monitor='val_accuracy', \n    patience=3, \n    verbose=1, \n    mode='max', \n    restore_best_weights=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the model \nhistory = model.fit(\n    x = train_generator, \n    validation_data = val_generator,\n    steps_per_epoch = step_train_size,\n    epochs = 10,\n    verbose = 1\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications import ResNet50\n\nnew_model = ResNet50(\n    weight = \"imagenet\",\n    include_top = False,\n    input_shape = (256, 256)\n)\n\nfor layer in new_model.layers:\n    layer.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_model = Sequential([\n    new_model,\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.MaxPooling2D(),\n    # Flatten layer\n    layers.Conv2D(512, (3,3), activation='relu'),\n    layers.Flatten(),\n    # Fully connected layers\n    layers.Dense(17, activation='softmax'), \n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = final_model.fit(\n    x = train_generator,\n    validation_data = val_generator,\n    steps_per_epoch = step_train_size,\n    epochs = 10,\n    verbose = 1\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##adding .jpg extension to image name in the sample submission file\nsample_submission = pd.read_csv('../input/planets-dataset/planet/planet/sample_submission.csv')\nsample_submission1 = sample_submission.copy()\nsample_submission1['image_name'] = sample_submission1['image_name'].apply(lambda x: '{}.jpg'.format(x))\nsample_submission1.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['training', 'validation'], loc='upper left')\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['training', 'validation'], loc='upper left')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" Divide the sample submission file into two splits,\n# first test1_df contains the first 40669 images \ntest_df1 = sample_submission1.iloc[:40669]['image_name'].reset_index().drop('index', axis =1)\ntest_df1.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#initialize imagedatagenerator for the test images and also rescaling\ntest_datagen = ImageDataGenerator(rescale = 1/255)\n\n#creating a generator for the images found in the first test image files\ntest_gen = test_datagen.flow_from_dataframe(dataframe=test_df1, \n                                            directory='/kaggle/input/planets-dataset/planet/planet/test-jpg/', \n                                            x_col=\"image_name\", \n                                            y_col=None, \n                                            batch_size=32,\n                                            seed=42,\n                                            shuffle=False, \n                                            class_mode='categorical', \n                                            target_size=(256,256))\n\nstep_test_size1 = int(np.ceil(test_gen.samples/test_gen.batch_size))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_gen.reset()\npred = final_model.predict(test_gen, steps=step_test_size1, verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_names = test_gen.filenames\n\n# Convert the predicted values to a dataframe and join two labels together if prob(occurrance of the label) > 0.5 \npred_tags = pd.DataFrame(pred)\npred_tags = pred_tags.apply(lambda x: ' '.join(np.array(labels)[x > 0.5]), axis = 1)\n\n#then the result should look like this \nresult1 = pd.DataFrame({'image_name': file_names, 'tags': pred_tags})\nresult1.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#second batch of the test dataset\nadditional_df = sample_submission1.iloc[40669:]['image_name'].reset_index().drop('index', axis =1)\nadditional_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating a generator for the second batch of test image files\ntest_gen1 = test_datagen.flow_from_dataframe(dataframe=additional_df, \n                                                directory='../input/planets-dataset/test-jpg-additional/test-jpg-additional', \n                                                x_col='image_name', \n                                                y_col=None, \n                                                batch_size=500, \n                                                shuffle=False, \n                                                class_mode=None, \n                                                target_size=(256,256))\n\nstep_test_size2 = int(np.ceil(test_gen1.samples/test_gen1.batch_size))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we reset the generator to avoid shuffling, then make prediction on the generator\ntest_gen1.reset()\npred1 = model1.predict(test_gen1, steps = step_test_size2, verbose = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this is to get the filenames in the generator using the attribute .filenames\nfile_names1 = test_gen1.filenames\n\n#convert the predicted values to a dataframe\n#join two labels together if the prob(occurrance of the label) > 0.5\npred_tags1 = pd.DataFrame(pred1)\npred_tags1 = pred_tags1.apply(lambda x: ''.join(np.array(labels)[x>0.5]), axis = 1)\n\nresult2 = pd.DataFrame({'image_name': file_names1, 'tags': pred_tags1})\nresult2.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Final result of the predicted tags for the test images,\n# we need to concat the first and second results in \n#that order to avoid shuffling the index\nfinal_df = pd.concat([result1, result2])\n\nfinal_df = final_df.reset_index().drop('index', axis =1)\n\nprint(final_df.shape)\nfinal_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove the .jpg extension from the image_name of the last_result \nfinal_df['image_name'] = final_df['image_name'].apply(lambda x: x[:-4])\nfinal_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finally, we save the result to a csv file using the .to_csv() \n# method and setting the index to false.\nfinal_df.to_csv('submission2.csv', index = False)","metadata":{},"execution_count":null,"outputs":[]}]}